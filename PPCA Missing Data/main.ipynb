{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3e2a94",
   "metadata": {},
   "source": [
    "# PPCA for Missing Data Imputation\n",
    "\n",
    "Objectives:\n",
    "1. Create synthetic low-rank Gaussian data and randomly remove 10% entries.\n",
    "2. Run Probabilistic PCA (EM) that natively handles missing values to jointly learn parameters and infer latent variables.\n",
    "3. Impute missing entries (posterior mean) and compare against ground-truth values using RMSE / MAE.\n",
    "\n",
    "We also compare with a simple baseline (mean imputation) to show PPCA advantage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974bc013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data: X_full shape (1000, 20), missing entries 1988 (9.9%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# I. Create synthetic data\n",
    "n = 1000   # samples\n",
    "d = 20     # observed dimension\n",
    "k_true = 3 # latent dimension\n",
    "\n",
    "# True parameters\n",
    "W_true = np.random.randn(d, k_true)\n",
    "# Make W well-conditioned\n",
    "U, _, Vt = np.linalg.svd(W_true, full_matrices=False)\n",
    "W_true = U @ np.diag(np.linspace(2.0,0.5,k_true)) @ Vt\n",
    "mu_true = np.random.randn(d) * 0.5\n",
    "sigma2_true = 0.1\n",
    "\n",
    "Z_true = np.random.randn(n, k_true)\n",
    "X_full = Z_true @ W_true.T + mu_true + np.random.randn(n, d) * math.sqrt(sigma2_true)\n",
    "\n",
    "# Introduce 10% missing at random\n",
    "missing_rate = 0.10\n",
    "mask = np.random.rand(n, d) > missing_rate  # True = observed\n",
    "X_obs = X_full.copy()\n",
    "X_obs[~mask] = np.nan\n",
    "\n",
    "print(f\"Generated data: X_full shape {X_full.shape}, missing entries {(~mask).sum()} ({(~mask).mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44710356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: sigma2=0.3736 change=1.55e+00\n",
      "Iter 10: sigma2=0.1063 change=2.61e-02\n",
      "Iter 20: sigma2=0.1058 change=2.92e-03\n",
      "Iter 30: sigma2=0.1058 change=2.85e-03\n",
      "Iter 40: sigma2=0.1058 change=2.84e-03\n",
      "Iter 50: sigma2=0.1058 change=2.84e-03\n",
      "Iter 60: sigma2=0.1058 change=2.84e-03\n",
      "Iter 70: sigma2=0.1058 change=2.84e-03\n",
      "Iter 80: sigma2=0.1058 change=2.84e-03\n",
      "Iter 90: sigma2=0.1058 change=2.84e-03\n",
      "Iter 100: sigma2=0.1058 change=2.84e-03\n",
      "Iter 110: sigma2=0.1058 change=2.84e-03\n",
      "Iter 120: sigma2=0.1058 change=2.84e-03\n",
      "Iter 130: sigma2=0.1058 change=2.84e-03\n",
      "Iter 140: sigma2=0.1058 change=2.84e-03\n",
      "Iter 150: sigma2=0.1058 change=2.84e-03\n",
      "Iter 160: sigma2=0.1058 change=2.84e-03\n",
      "Iter 170: sigma2=0.1058 change=2.84e-03\n",
      "Iter 180: sigma2=0.1058 change=2.84e-03\n",
      "Iter 190: sigma2=0.1058 change=2.84e-03\n",
      "Iter 200: sigma2=0.1058 change=2.84e-03\n",
      "Iter 210: sigma2=0.1058 change=2.84e-03\n",
      "Iter 220: sigma2=0.1058 change=2.84e-03\n",
      "Iter 230: sigma2=0.1058 change=2.84e-03\n",
      "Iter 240: sigma2=0.1058 change=2.84e-03\n",
      "Iter 250: sigma2=0.1058 change=2.84e-03\n",
      "Iter 260: sigma2=0.1058 change=2.84e-03\n",
      "Iter 270: sigma2=0.1058 change=2.84e-03\n",
      "Iter 280: sigma2=0.1058 change=2.84e-03\n",
      "Iter 290: sigma2=0.1058 change=2.84e-03\n",
      "Learned sigma2: 0.10575681302936554\n"
     ]
    }
   ],
   "source": [
    "def ppca_em_missing(X, k, max_iter=200, tol=1e-5, verbose=False, seed=0):\n",
    "    \"\"\"PPCA EM handling missing values (NaNs) via per-sample observed mask.\n",
    "    X: (n,d) with NaNs for missing\n",
    "    Returns model dict and posterior means for latent variables.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = np.asarray(X)\n",
    "    n, d = X.shape\n",
    "    mask_obs = ~np.isnan(X)  # boolean\n",
    "    # Initialize: fill NaNs with column means for a quick start\n",
    "    col_means = np.nanmean(X, axis=0)\n",
    "    X_filled = np.where(mask_obs, X, col_means)\n",
    "    mu = np.nanmean(X, axis=0)\n",
    "    # init W random, isotropic noise\n",
    "    W = rng.normal(scale=0.1, size=(d, k))\n",
    "    sigma2 = 1.0\n",
    "    I_k = np.eye(k)\n",
    "\n",
    "    ll_prev = -np.inf\n",
    "    for it in range(max_iter):\n",
    "        # E-step: compute Ez_i and Ezz_i per sample using only observed dims\n",
    "        Ez = np.zeros((n, k))\n",
    "        Ezz = np.zeros((n, k, k))\n",
    "        ll = 0.0\n",
    "        for i in range(n):\n",
    "            obs = mask_obs[i]\n",
    "            x_i_obs = X[i, obs]\n",
    "            W_obs = W[obs]\n",
    "            mu_obs = mu[obs]\n",
    "            M_i = W_obs.T @ W_obs + sigma2 * I_k\n",
    "            M_i_inv = inv(M_i)\n",
    "            Ez_i = (x_i_obs - mu_obs) @ W_obs @ M_i_inv\n",
    "            Ez[i] = Ez_i\n",
    "            Ezz[i] = sigma2 * M_i_inv + np.outer(Ez_i, Ez_i)\n",
    "            # Accumulate approximate log-likelihood (only constants across iters matter for convergence check)\n",
    "            # Not strictly needed; we'll use parameter diff for stopping.\n",
    "        # M-step: update mu using observed residuals with current latent expectations\n",
    "        # Impute expected X for missing dims to update mu and W.\n",
    "        X_recon = np.zeros_like(X_filled)\n",
    "        for i in range(n):\n",
    "            X_recon[i] = mu + Ez[i] @ W.T\n",
    "        # Use observed entries where present, else reconstructed for purpose of mean centering\n",
    "        X_completed = np.where(mask_obs, X, X_recon)\n",
    "        mu = X_completed.mean(axis=0)\n",
    "        Xc = X_completed - mu\n",
    "        # Update W using summed cross-covariances restricted to observed entries per sample\n",
    "        # Accumulate Sx = sum_i xci_obs Ez_i^T and sum_Ezz\n",
    "        Sx = np.zeros((d, k))\n",
    "        sum_Ezz = np.zeros((k, k))\n",
    "        for i in range(n):\n",
    "            obs = mask_obs[i]\n",
    "            xci_obs = Xc[i, obs]\n",
    "            Sx[obs] += np.outer(xci_obs, Ez[i])\n",
    "            sum_Ezz += Ezz[i]\n",
    "        W_new = Sx @ inv(sum_Ezz)\n",
    "        # Update sigma^2 using observed residuals only\n",
    "        res_sum = 0.0\n",
    "        obs_count = 0\n",
    "        for i in range(n):\n",
    "            obs = mask_obs[i]\n",
    "            xci_obs = Xc[i, obs]\n",
    "            recon_obs = W_new[obs] @ Ez[i]\n",
    "            diff = xci_obs - recon_obs\n",
    "            res_sum += diff @ diff\n",
    "            # Add trace term from latent covariance\n",
    "            res_sum += np.trace(W_new[obs] @ (Ezz[i] - np.outer(Ez[i], Ez[i])) @ W_new[obs].T)\n",
    "            obs_count += obs.sum()\n",
    "        sigma2_new = res_sum / obs_count\n",
    "        # Convergence check\n",
    "        param_change = np.linalg.norm(W_new - W) / (np.linalg.norm(W) + 1e-12) + abs(sigma2_new - sigma2)/(sigma2 + 1e-12)\n",
    "        W = W_new\n",
    "        sigma2 = max(sigma2_new, 1e-8)\n",
    "        if verbose and it % 10 == 0:\n",
    "            print(f\"Iter {it}: sigma2={sigma2:.4f} change={param_change:.2e}\")\n",
    "        if param_change < tol:\n",
    "            break\n",
    "    return {'mu': mu, 'W': W, 'sigma2': sigma2, 'Ez': Ez, 'Ezz': Ezz}\n",
    "\n",
    "model = ppca_em_missing(X_obs, k=3, max_iter=300, tol=1e-5, verbose=True)\n",
    "print(\"Learned sigma2:\", model['sigma2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0abc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing entries: 1988\n",
      "PPCA   RMSE: 0.3560  MAE: 0.2821\n",
      "Mean   RMSE: 0.6159  MAE: 0.4665\n",
      "   feature  ppca_rmse  mean_rmse\n",
      "0        9   0.302978   0.421618\n",
      "1       18   0.378228   0.593970\n",
      "2       11   0.382183   0.504472\n"
     ]
    }
   ],
   "source": [
    "# II / III. Impute missing values and compare to truth\n",
    "\n",
    "mu, W, Ez = model['mu'], model['W'], model['Ez']\n",
    "X_ppca_recon = Ez @ W.T + mu  # posterior mean of complete data (ignoring noise)\n",
    "\n",
    "# Extract only originally missing positions\n",
    "missing_idx = np.where(~mask)  # tuple (rows, cols)\n",
    "true_missing_vals = X_full[missing_idx]\n",
    "imputed_ppca = X_ppca_recon[missing_idx]\n",
    "\n",
    "# Baseline: column mean imputation (using observed-only means)\n",
    "col_mean_obs = np.nanmean(X_obs, axis=0)\n",
    "imputed_mean = col_mean_obs[missing_idx[1]]\n",
    "\n",
    "rmse_ppca = np.sqrt(np.mean((imputed_ppca - true_missing_vals)**2))\n",
    "mae_ppca = np.mean(np.abs(imputed_ppca - true_missing_vals))\n",
    "rmse_mean = np.sqrt(np.mean((imputed_mean - true_missing_vals)**2))\n",
    "mae_mean = np.mean(np.abs(imputed_mean - true_missing_vals))\n",
    "\n",
    "print(f\"Missing entries: {true_missing_vals.size}\")\n",
    "print(f\"PPCA   RMSE: {rmse_ppca:.4f}  MAE: {mae_ppca:.4f}\")\n",
    "print(f\"Mean   RMSE: {rmse_mean:.4f}  MAE: {mae_mean:.4f}\")\n",
    "\n",
    "# Optional: visualize a few feature distributions (true vs imputed)\n",
    "import pandas as pd\n",
    "sel_features = np.random.choice(d, 3, replace=False)\n",
    "rows = []\n",
    "for f in sel_features:\n",
    "    idx_f = (missing_idx[1] == f)\n",
    "    rows.append({\n",
    "        'feature': f,\n",
    "        'ppca_rmse': np.sqrt(np.mean((imputed_ppca[idx_f]-true_missing_vals[idx_f])**2)),\n",
    "        'mean_rmse': np.sqrt(np.mean((imputed_mean[idx_f]-true_missing_vals[idx_f])**2))\n",
    "    })\n",
    "print(pd.DataFrame(rows))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
